{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f266a17e-c864-4f63-8db9-2c3caed40c99",
   "metadata": {},
   "source": [
    "# Search Similar 3D Meshes\n",
    "\n",
    "In this tutorial, we will learn how to build a 3D mesh search pipeline with Jina. In particular, we will be building a search pipeline for 3D models in GLB format.\n",
    "\n",
    "Just like other data types, the 3D meshes search pipeline consists of **loading**, **encoding** and **indexing** the data. We can search the data after they are indexed.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Let's first install the following PyPI dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ac9e1a-1574-42ca-a5d5-d89466a065ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow trimesh pyrender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a6cac-b561-4b99-aacd-9498eb1946b5",
   "metadata": {},
   "source": [
    "## Load GLB data\n",
    "\n",
    "First, given a `glb` file, how do we load and craft the `glb` into a Document so that we can process and encode?\n",
    "Let's use `trimesh` to build an Executor for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3a4413-4d67-4ae0-aa8f-5aaa4c428d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "from typing import Optional\n",
    "from docarray import Document, DocumentArray\n",
    "from jina import Executor, requests\n",
    "\n",
    "def as_mesh(scene: trimesh.Scene) -> Optional[trimesh.Trimesh]:\n",
    "    if len(scene.geometry) == 0:\n",
    "        return None\n",
    "    return trimesh.util.concatenate(\n",
    "        tuple(trimesh.Trimesh(vertices=g.vertices, faces=g.faces)\n",
    "            for g in scene.geometry.values()))\n",
    "\n",
    "\n",
    "class GlbCrafter(Executor):\n",
    "    @requests(on=['/index', '/search'])\n",
    "    def craft(self, docs: DocumentArray, **kwargs):\n",
    "        for d in docs:\n",
    "            mesh = trimesh.load_mesh(d.uri)\n",
    "            d.tensor = as_mesh(trimesh.load_mesh(d.uri)).sample(2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f61fa4a-2a7c-4a57-af62-7ad67a2f8103",
   "metadata": {
    "tags": []
   },
   "source": [
    "We first load the data of each `glb` file as Python object.\n",
    "We will use the `trimesh` package to represents the `glb` data in the form of triangular meshes.\n",
    "The loaded object is of type `trimesh.Scene` which may contain one or more triangular mesh geometries.\n",
    "We combine all the meshes in the `Scene` to create a single `Trimesh` using `as_mesh`.\n",
    "Then we can sample surfaces from a single mesh geometry.\n",
    "The sampled surface will be made from 2048 points in 3D space and hence the shape of the `ndarray` representing each 3D model will be `(2048, 3)`.\n",
    "\n",
    "## Encode 3D Model\n",
    "\n",
    "Once we convert each `glb` model into an `ndarray`, encoding the inputs becomes straightforward.\n",
    "We will use our pre-trained `pointnet` to encode the data. The model looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200ca462-b961-4df4-b29d-4dced55f4cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(ckpt_path):\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from keras import layers\n",
    "    \n",
    "    def conv_bn(x, filters):\n",
    "        x = layers.Conv1D(filters, kernel_size=1, padding='valid')(x)\n",
    "        x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "        return layers.Activation('relu')(x)\n",
    "    \n",
    "    \n",
    "    def dense_bn(x, filters):\n",
    "        x = layers.Dense(filters)(x)\n",
    "        x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "        return layers.Activation('relu')(x)\n",
    "    \n",
    "    \n",
    "    def tnet(inputs, num_features):\n",
    "        class OrthogonalRegularizer(keras.regularizers.Regularizer):\n",
    "            def __init__(self, num_features_, l2reg=0.001):\n",
    "                self.num_features = num_features_\n",
    "                self.l2reg = l2reg\n",
    "                self.eye = tf.eye(self.num_features)\n",
    "    \n",
    "            def __call__(self, x):\n",
    "                x = tf.reshape(x, (-1, self.num_features, self.num_features))\n",
    "                xxt = tf.tensordot(x, x, axes=(2, 2))\n",
    "                xxt = tf.reshape(xxt, (-1, self.num_features, self.num_features))\n",
    "                return tf.reduce_sum(self.l2reg * tf.square(xxt - self.eye))\n",
    "    \n",
    "            def get_config(self):\n",
    "                return {'num_features': self.num_features,\n",
    "                        'l2reg': self.l2reg,\n",
    "                        'eye': self.eye.numpy()}\n",
    "    \n",
    "        bias = keras.initializers.Constant(np.eye(num_features).flatten())\n",
    "        reg = OrthogonalRegularizer(num_features)\n",
    "    \n",
    "        x = conv_bn(inputs, 32)\n",
    "        x = conv_bn(x, 64)\n",
    "        x = conv_bn(x, 512)\n",
    "        x = layers.GlobalMaxPooling1D()(x)\n",
    "        x = dense_bn(x, 256)\n",
    "        x = dense_bn(x, 128)\n",
    "        x = layers.Dense(\n",
    "            num_features * num_features,\n",
    "            kernel_initializer='zeros',\n",
    "            bias_initializer=bias,\n",
    "            activity_regularizer=reg,\n",
    "        )(x)\n",
    "        feat_T = layers.Reshape((num_features, num_features))(x)\n",
    "        return layers.Dot(axes=(2, 1))([inputs, feat_T])\n",
    "\n",
    "    inputs = keras.Input(shape=(2048, 3))\n",
    "    x = tnet(inputs, 3)\n",
    "    x = conv_bn(x, 32)\n",
    "    x = conv_bn(x, 32)\n",
    "    x = tnet(x, 32)\n",
    "    x = conv_bn(x, 32)\n",
    "    x = conv_bn(x, 64)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = dense_bn(x, 128)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(1, activation='softmax')(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='pointnet')\n",
    "    intermediate_layer_model = keras.Model(inputs=model.input,\n",
    "                                           outputs=model.get_layer(f'dense_1').output)\n",
    "    intermediate_layer_model.load_weights(ckpt_path)\n",
    "    return intermediate_layer_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c8c06f-34f0-4471-b576-94d24c279e99",
   "metadata": {},
   "source": [
    "With the above model, we can then build our `pointnet` executor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f485cd-0f0d-4bbc-9979-ecb6505557dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PNEncoder(Executor):\n",
    "    def __init__(self, ckpt_path: str, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embedding_model = get_model(ckpt_path=ckpt_path)\n",
    "\n",
    "    @requests(on=['/index', '/search'])\n",
    "    def encode(self, docs: DocumentArray, **kwargs):\n",
    "        docs.embeddings = self.embedding_model.predict(docs.tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54992f1-b229-43cc-9a17-8aa6a27e2b7c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b>  Instead of iterating over each doc to set its embedding, we can directly get the tensors of all docs in `docs` at once by using the attribute `blobs` and set the embeddings of all docs in `docs` at once by using the attribute `embeddings`.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fb7295-8303-4415-9142-cd65ecc548b5",
   "metadata": {},
   "source": [
    "## Index the data\n",
    "\n",
    "Let's also build an indexer to index the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f837438b-5a11-4dbd-9e9a-481fc685d552",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyIndexer(Executor):\n",
    "    _docs = DocumentArray()\n",
    "\n",
    "    @requests(on='/index')\n",
    "    def index(self, docs: DocumentArray, **kwargs):\n",
    "        self._docs.extend(docs)\n",
    "\n",
    "    @requests(on='/search')\n",
    "    def search(self, docs: DocumentArray, **kwargs):\n",
    "        docs.match(self._docs, limit=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5170d2f-6dd8-4bce-95d8-a8883892ca95",
   "metadata": {
    "tags": []
   },
   "source": [
    "The above indexer simply uses `DocumentArray` to store all the index docs and leverages the `match` function of `DocumentArray` to match the query with docs indexed.\n",
    "\n",
    "## Visualize 3D Model\n",
    "\n",
    "Finally, let's also build the `GlbVisualizer` to visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9d91b3-c6d8-4b77-a142-befe32960127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrender\n",
    "import pyglet\n",
    "from pyglet import clock\n",
    "from pyglet.gl import Config\n",
    "from pyrender import Viewer\n",
    "\n",
    "\n",
    "def _init_and_start_app(self):\n",
    "        TARGET_OPEN_GL_MAJOR = 4  # Target OpenGL Major Version\n",
    "        TARGET_OPEN_GL_MINOR = 1\n",
    "        MIN_OPEN_GL_MAJOR = 3     # Minimum OpenGL Major Version\n",
    "        MIN_OPEN_GL_MINOR = 3     # Minimum OpenGL Minor Version\n",
    "        confs = [Config(sample_buffers=1, samples=4,\n",
    "                        depth_size=24,\n",
    "                        double_buffer=True,\n",
    "                        major_version=TARGET_OPEN_GL_MAJOR,\n",
    "                        minor_version=TARGET_OPEN_GL_MINOR),\n",
    "                 Config(depth_size=24,\n",
    "                        double_buffer=True,\n",
    "                        major_version=TARGET_OPEN_GL_MAJOR,\n",
    "                        minor_version=TARGET_OPEN_GL_MINOR),\n",
    "                 Config(sample_buffers=1, samples=4,\n",
    "                        depth_size=24,\n",
    "                        double_buffer=True,\n",
    "                        major_version=MIN_OPEN_GL_MAJOR,\n",
    "                        minor_version=MIN_OPEN_GL_MINOR),\n",
    "                 Config(depth_size=24,\n",
    "                        double_buffer=True,\n",
    "                        major_version=MIN_OPEN_GL_MAJOR,\n",
    "                        minor_version=MIN_OPEN_GL_MINOR)]\n",
    "        for conf in confs:\n",
    "            try:\n",
    "                super(Viewer, self).__init__(config=conf, resizable=True,\n",
    "                                             width=self._viewport_size[0],\n",
    "                                             height=self._viewport_size[1])\n",
    "                break\n",
    "            except pyglet.window.NoSuchConfigException:\n",
    "                pass\n",
    "\n",
    "        if not self.context:\n",
    "            raise ValueError('Unable to initialize an OpenGL 3+ context')\n",
    "\n",
    "        clock.schedule_interval(\n",
    "            Viewer._time_event, 1.0 / self.viewer_flags['refresh_rate'], self\n",
    "        )\n",
    "        self.switch_to()\n",
    "        self.set_caption(self.viewer_flags['window_title'])\n",
    "\n",
    "\n",
    "class GlbVisualizer:\n",
    "    def __init__(self, search_doc, matches=None):\n",
    "        self.search_doc = search_doc\n",
    "        self.matches = matches\n",
    "        self.orig_func = pyrender.Viewer._init_and_start_app\n",
    "        pyrender.Viewer._init_and_start_app = _init_and_start_app\n",
    "\n",
    "    def visualize(self):\n",
    "        self.add(self.search_doc.uri, 'Query Doc')\n",
    "        if self.matches:\n",
    "            for i, match in enumerate(self.matches, start=1):\n",
    "                self.add(match.uri, f'Top {i} Match')\n",
    "        pyglet.app.run()\n",
    "\n",
    "    def add(self, uri, title):\n",
    "        fuze_trimesh = as_mesh(trimesh.load(uri))\n",
    "        mesh = pyrender.Mesh.from_trimesh(fuze_trimesh)\n",
    "        scene = pyrender.Scene()\n",
    "        scene.add(mesh)\n",
    "\n",
    "        pyrender.Viewer(\n",
    "            scene,\n",
    "            use_raymond_lighting=True,\n",
    "            viewer_flags={\n",
    "                'rotate': True,\n",
    "                'window_title': title, \n",
    "                'caption': [{\n",
    "                    'font_name': 'OpenSans-Regular',\n",
    "                    'font_pt': 30,\n",
    "                    'color': None,\n",
    "                    'scale': 1.0,\n",
    "                    'location': 4,\n",
    "                    'text': title\n",
    "                }]\n",
    "            },\n",
    "        )\n",
    "        \n",
    "    def __del__(self):\n",
    "        pyrender.Viewer._init_and_start_app = self.orig_func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d1b115-e496-40e1-a7de-1c3eee9469c9",
   "metadata": {},
   "source": [
    "The visualizer uses `pyrender` to render the query and match results.\n",
    "Since we want to display multiple models at once, we need to patch the `_init_and_start_app` function to delay the start of pyrender app after all viewers are initialized.\n",
    "\n",
    "\n",
    "## Index, Search and Visualize Data\n",
    "\n",
    "Download the pre-trained PNEncoder model [here](https://github.com/jina-ai/example-3D-model/tree/main/executors/pn_encoder/ckpt) into `model/ckpt`.\n",
    "Also, store your index/search data in `data/`.\n",
    "We can then put the executors into a flow and use the flow to perform indexing and searching.\n",
    "Finally, we use the `GlbVisualizer` built earlier to visualize our data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b597d1a-bbde-4af9-a49d-5b478fdf070b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Getting data:</b> If you dont have .glb data already, you can download some samples from here (https://shapenet.org/), after creating a free account.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfac25f-8c59-4856-bcb2-e813360491b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jina import Flow\n",
    "\n",
    "with Flow().add(uses=GlbCrafter).add(uses=PNEncoder, uses_with={'ckpt_path': 'model/ckpt/ckpt_True'}).add(uses=MyIndexer) as f:\n",
    "    f.index(DocumentArray.from_files('data/*.glb'))\n",
    "    results = f.search(Document(uri='data/ShapeNetV2_airplane_aeroplane_plane_0.glb'), return_results=True)\n",
    "    doc = results[0]\n",
    "    # visualize top 3 matches, since we also index query doc, exclude the top 1 match as it is the query doc\n",
    "    visualizer = GlbVisualizer(doc, matches=doc.matches).visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fadb10-d299-4d5d-a542-df220cf8af1d",
   "metadata": {},
   "source": [
    "This is how the flow we built looks like:\n",
    "![flow](flow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f3a513-1d8c-4192-affa-5cb51bc3f108",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Now let's take a look at the search results! Below is the `rifle_16.glb` 3D model we would like to search for:\n",
    "\n",
    "![Query doc](query_doc.gif)\n",
    "\n",
    "\n",
    "And the following are the top 3 matches:\n",
    "\n",
    "![Top 1](top_1.gif)\n",
    "\n",
    "![Top 2](top_2.gif)\n",
    "\n",
    "![Top 3](top_3.gif)\n",
    "\n",
    "**Congratulations!** You have just built a 3D Mesh Search Pipeline!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
